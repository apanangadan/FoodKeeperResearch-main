{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aacaef34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ## Evaluation Notebook\n",
    "\n",
    "# !python -m spacy download en_core_web_sm\n",
    "#pip install spacy\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import re\n",
    "import os\n",
    "from spacy import displacy\n",
    "from sklearn import metrics\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "FOODKEEPER_PATH = \"datasets/FoodKeeper-Data.xls\"\n",
    "TRAINING_DATA_PATH = \"datasets/data.csv\"\n",
    "MODEL_PATH = \"output/model-last\"\n",
    "TEST_DATA_PATH = \"datasets/test_data.csv\"\n",
    "REAL_TWITTER_DATA_PATH = \"datasets/data.csv\"\n",
    "PREDICTED_DATA_PATH = \"datasets/new_test_tweets.csv\"\n",
    "#STARTING_KEYWORD_COUNT = 10\n",
    "#TRAINING_LOOP_ITERATIONS = 3\n",
    "#REQUIRED_KEYWORDS = 3\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b58b25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0  1\n",
      "0   just microwaved a kashi chicken and spinach th...  1\n",
      "1   @amyg0716 thats really sad i wolud hate that! ...  1\n",
      "2   @DTizzler and it took me my entire walk to the...  0\n",
      "3   just finished cooking spag bol from scratch.. ...  1\n",
      "4   Oh noooooo Kath is back from Annual Leave!!!!!...  0\n",
      "..                                                ... ..\n",
      "78  sick roomie gave me her cold my throats sore (...  0\n",
      "79  No flying to Ponca City today for breakfast Oa...  1\n",
      "80  just walked by marks&amp;spencers food n didn'...  1\n",
      "81  if lucas till and taylor swift start dating i ...  0\n",
      "82                          Bed time. Back to reality  0\n",
      "\n",
      "[83 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "food_data = pd.read_excel(FOODKEEPER_PATH, sheet_name = \"Product\")\n",
    "all_data = pd.read_csv(TRAINING_DATA_PATH,index_col = False, header = None)\n",
    "#live_tweets = pd.read_csv(PREDICTED_DATA_PATH, skiprows = [0], header=None)  \n",
    "checked_tweets = pd.read_csv(TEST_DATA_PATH, skiprows = [0], header=None)  \n",
    "print(checked_tweets)\n",
    "#Gathers all the keywords from the FoodKeeper database\n",
    "#def foodKeeperInfo():\n",
    "def foodKeeperInfo(spreadsheet):\n",
    "    keywords = []\n",
    "    #for word in food_data['Name']: # food_data['Keywords']:\n",
    "    for word in spreadsheet[0]:\n",
    "        word = word.replace(\" or \", \" \") # TO DO: break up phrases with commas like \"Pastries, danish\" into separate words\n",
    "        word = re.sub('[/,]', ' ', word)\n",
    "        word = word.lstrip()\n",
    "        word = word.rstrip()\n",
    "        if word.lower() not in keywords: \n",
    "            keywords.append(word.lower())\n",
    "\n",
    "    #print(\"Total foodkeeper food names: \" + str(len(keywords)))        \n",
    "    #for element in sorted(keywords):\n",
    "        #print(element)\n",
    "    return keywords\n",
    "\n",
    "\n",
    "def preProcess(tweet):\n",
    "    #Converts a tweet to lowercase, replaces anyusername w/ <USERNAME> and URLS with <URL>\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub('@[a-zA-z0-9]*', '', tweet)              # <USERNAME>\n",
    "    tweet = re.sub('http[a-zA-z0-9./:]*', '', tweet)       # <URL>\n",
    "    tweet = re.sub('[.,-]*', '', tweet)\n",
    "    tweet = re.sub('&amp;', 'and', tweet)\n",
    "    return tweet\n",
    "\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "foodKeeperKeywords = foodKeeperInfo(checked_tweets)\n",
    "#print(foodKeeperKeywords)\n",
    "\n",
    "#for i in range(len(all_data[0])):\n",
    "     #all_data[0][i] = unProcess(all_data[0][i])\n",
    "\n",
    "# select tweets which contain one of the foodKeeperKeywords\n",
    "selected_tweets = []\n",
    "for tweet in all_data[0]:\n",
    "    for keyword in foodKeeperKeywords:\n",
    "        if all(word in tweet for word in keyword):\n",
    "            selected_tweets.append(tweet)\n",
    "            break\n",
    "# then select 250 random tweets of these; this is the test_data\n",
    "test_data = random.sample(selected_tweets, 250)\n",
    "test_data_df = pd.DataFrame(test_data, columns=['Random Tweet'])\n",
    "# save test_data in a \"new_test_tweets.csv\" file\n",
    "test_data_df.to_csv('datasets/random_test_tweets.csv', index=False)\n",
    "\n",
    "# Read the random_test_tweets.csv file\n",
    "random_test_data_df = pd.read_csv('datasets/random_test_tweets.csv')\n",
    "\n",
    "# Read the new_test_tweets.csv file\n",
    "new_test_data_df = pd.read_csv('datasets/new_test_tweets.csv')\n",
    "\n",
    "# Update the 'Tweet' column in new_test_data_df with the random tweets from random_test_data_df\n",
    "new_test_data_df['Tweet'] = random_test_data_df['Random Tweet']\n",
    "\n",
    "# Save the updated new_test_data_df to the new_test_tweets.csv file\n",
    "new_test_data_df.to_csv('datasets/new_test_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d512732",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages/spacy/util.py:887: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.5.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages/spacy/util.py:887: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.5.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chicken', 'milk', 'None', 'None', 'None', 'eggs', 'potatoes', 'None', 'None', 'None', 'None', 'None', 'salsa', 'salsa', 'None', 'None', 'ice cream', 'None', 'None', 'None', 'None', 'None', 'crab meat', 'butter', 'crab legs', 'crab legs', 'shellfish', 'quail', 'None', 'None', 'None', 'None', 'pastrami', 'pastrami', 'parsley', 'Some', 'None', 'None', 'None', 'chocolate', 'None', '@Sabbyaz', 'chocolate', 'None', 'None', 'None', 'buttermilk', 'popcorn', 'peas', 'None', 'None', 'None', 'pork', 'None', 'None', 'string cheese', 'cheese', 'None', 'None', 'chocolate', 'cheese', 'None', 'cheese', 'None', 'rabbit', 'None', 'None', 'None', 'pizza', 'Pizza', 'Pizza', 'pizza', 'pizza', 'rice', 'None', 'None', 'None', 'None', 'None', 'None', 'honey', 'None', 'None']\n",
      "Ratio of incorrect predictions:  0.133 \n",
      "\n",
      "Count Predicted Word      Accuracy  \n",
      "---------------------------\n",
      "1     chicken             Correct   \n",
      "2     milk                Correct   \n",
      "3     None                Correct   \n",
      "4     None                Wrong     \n",
      "5     None                Correct   \n",
      "6     eggs                Correct   \n",
      "7     potatoes            Correct   \n",
      "8     None                Correct   \n",
      "9     None                Wrong     \n",
      "10    None                Wrong     \n",
      "11    None                Correct   \n",
      "12    None                Correct   \n",
      "13    salsa               Correct   \n",
      "14    salsa               Correct   \n",
      "15    None                Correct   \n",
      "16    None                Wrong     \n",
      "17    ice cream           Correct   \n",
      "18    None                Correct   \n",
      "19    None                Correct   \n",
      "20    None                Correct   \n",
      "21    None                Correct   \n",
      "22    None                Correct   \n",
      "23    crab meat           Correct   \n",
      "24    butter              Correct   \n",
      "25    crab legs           Correct   \n",
      "26    crab legs           Correct   \n",
      "27    shellfish           Correct   \n",
      "28    quail               Correct   \n",
      "29    None                Correct   \n",
      "30    None                Correct   \n",
      "31    None                Correct   \n",
      "32    None                Correct   \n",
      "33    pastrami            Correct   \n",
      "34    pastrami            Correct   \n",
      "35    parsley             Correct   \n",
      "36    Some                Wrong     \n",
      "37    None                Correct   \n",
      "38    None                Correct   \n",
      "39    None                Wrong     \n",
      "40    chocolate           Correct   \n",
      "41    None                Correct   \n",
      "42    @Sabbyaz            Correct   \n",
      "43    chocolate           Correct   \n",
      "44    None                Correct   \n",
      "45    None                Correct   \n",
      "46    None                Wrong     \n",
      "47    buttermilk          Correct   \n",
      "48    popcorn             Correct   \n",
      "49    peas                Correct   \n",
      "50    None                Correct   \n",
      "51    None                Correct   \n",
      "52    None                Correct   \n",
      "53    pork                Correct   \n",
      "54    None                Wrong     \n",
      "55    None                Correct   \n",
      "56    string cheese       Correct   \n",
      "57    cheese              Correct   \n",
      "58    None                Correct   \n",
      "59    None                Correct   \n",
      "60    chocolate           Correct   \n",
      "61    cheese              Correct   \n",
      "62    None                Correct   \n",
      "63    cheese              Correct   \n",
      "64    None                Wrong     \n",
      "65    rabbit              Wrong     \n",
      "66    None                Correct   \n",
      "67    None                Correct   \n",
      "68    None                Correct   \n",
      "69    pizza               Correct   \n",
      "70    Pizza               Correct   \n",
      "71    Pizza               Correct   \n",
      "72    pizza               Correct   \n",
      "73    pizza               Correct   \n",
      "74    rice                Correct   \n",
      "75    None                Correct   \n",
      "76    None                Correct   \n",
      "77    None                Correct   \n",
      "78    None                Correct   \n",
      "79    None                Correct   \n",
      "80    None                Wrong     \n",
      "81    honey               Correct   \n",
      "82    None                Correct   \n",
      "83    None                Correct   \n",
      "Number of True Positives:  35 \n",
      "\n",
      "Ratio of True Positives:  0.422 \n",
      "\n",
      "Number of True Negatives:  37 \n",
      "\n",
      "Ratio of True Negatives:  0.446 \n",
      "\n",
      "Number of False Negatives:  9 \n",
      "\n",
      "Ratio of False Negatives:  0.108 \n",
      "\n",
      "Number of False Positives:  2 \n",
      "\n",
      "Ratio of False Positives:  0.024 \n",
      "\n",
      "Precision:  0.9459459459459459\n",
      "Recall:  0.7954545454545454\n"
     ]
    }
   ],
   "source": [
    "# code with spacy\n",
    "\n",
    "    \n",
    "def ent_recognize(text):\n",
    "    doc = nlp(text)\n",
    "    displacy.render(doc,style = \"ent\")\n",
    "    \n",
    "def predict(tweet):\n",
    "    doc = nlp(str(tweet))\n",
    "    if doc.ents:\n",
    "        displacy.render(doc,style = \"ent\")\n",
    "\n",
    "# update this function to return the individual word\n",
    "def returnPrediction(tweet):\n",
    "    nlp = spacy.load(MODEL_PATH)\n",
    "    doc = nlp(str(tweet))\n",
    "    #--words = [] # lines starting with #-- are for future task of getting a list of multiple foods from a single tweet\n",
    "    for word in doc.ents:\n",
    "        if(word.label_ == 'FOOD'):\n",
    "            #--words.append(word.text)\n",
    "            return word.text\n",
    "    #--return words\n",
    "    #if doc.ents:\n",
    "    #    return 1\n",
    "    #else:\n",
    "    #    return 0\n",
    "    \n",
    "def get_predictions():\n",
    "    predictions = []\n",
    "    #for tweet in test_data['tweet'].tolist():\n",
    "    for tweet in checked_tweets[0].tolist():\n",
    "        predictions.append(str(returnPrediction(tweet)))\n",
    "    return predictions\n",
    "predictions = get_predictions()\n",
    "def eval_model():\n",
    "    nlp = spacy.load(MODEL_PATH)\n",
    "    #predictions = get_predictions()\n",
    "    #tweets = test_data['tweet'].tolist()\n",
    "    tweets = new_test_data_df['Tweet'].tolist()\n",
    "    #Displays the ratio of correct words\n",
    "    numWrong = 0\n",
    "    listOfIncorrect = []\n",
    "    for i in range(len(checked_tweets)):\n",
    "        # logic for determining if model's prediction matches human prediction\n",
    "        if str(predictions[i]) != 'None' and checked_tweets[1][i] == 0:\n",
    "            numWrong += 1\n",
    "            listOfIncorrect.append(\"Wrong\")\n",
    "        elif str(predictions[i]) != 'None' and checked_tweets[1][i] == 1:\n",
    "            listOfIncorrect.append('Correct')\n",
    "        elif str(predictions[i]) == 'None' and checked_tweets[1][i] == 0:\n",
    "            listOfIncorrect.append('Correct')\n",
    "        else:\n",
    "            numWrong += 1\n",
    "            listOfIncorrect.append(\"Wrong\")\n",
    "    print(\"Ratio of incorrect predictions: \", round(numWrong/len(checked_tweets),3), \"\\n\")\n",
    "    \n",
    "    print(\"{:<6s}{:<20s}{:<10s}\".format(\"Count\", \"Predicted Word\", \"Accuracy\"))\n",
    "    print(\"---------------------------\")\n",
    "\n",
    "    # Iterate over the corresponding elements of the two lists with count\n",
    "    for count, (item1, item2) in enumerate(zip(predictions, listOfIncorrect), start=1):\n",
    "        # Format and print each row\n",
    "        print(\"{:<6d}{:<20s}{:<10s}\".format(count, item1, item2))\n",
    "\n",
    "def show_tp():\n",
    "    counter = 0\n",
    "    #tweets = checked_tweets[0].tolist()\n",
    "    #predictions = get_predictions()\n",
    "    for i in range(len(checked_tweets)):\n",
    "        if str(predictions[i]) != 'None' and checked_tweets[1][i] == 1:\n",
    "            #print(\"True positives:\", tweets[i], \"\\n\")\n",
    "            counter += 1\n",
    "    print(\"Number of True Positives: \", counter, \"\\n\")\n",
    "    print(\"Ratio of True Positives: \", round(counter/len(checked_tweets),3), \"\\n\")\n",
    "    return counter\n",
    "    \n",
    "def show_tn():\n",
    "    counter = 0\n",
    "    #predictions = get_predictions()\n",
    "    #tweets = checked_tweets[0].tolist()\n",
    "    for i in range(len(checked_tweets)):\n",
    "        if str(predictions[i]) == 'None' and checked_tweets[1][i] == 0:\n",
    "            #print(\"True Negative:\", tweets[i], \"\\n\")\n",
    "            counter += 1\n",
    "    print(\"Number of True Negatives: \", counter, \"\\n\")\n",
    "    print(\"Ratio of True Negatives: \", round(counter/len(checked_tweets),3), \"\\n\")\n",
    "    return counter\n",
    "    \n",
    "def show_fn():\n",
    "    #predictions = get_predictions()\n",
    "    #tweets = checked_tweets[0].tolist()\n",
    "    counter = 0\n",
    "    for i in range(len(checked_tweets)):\n",
    "        if str(predictions[i]) == 'None' and checked_tweets[1][i] == 1:\n",
    "            #print(\"False Negative:\", tweets[i], \"\\n\")\n",
    "            counter += 1\n",
    "    print(\"Number of False Negatives: \", counter, \"\\n\")\n",
    "    print(\"Ratio of False Negatives: \", round(counter/len(checked_tweets),3), \"\\n\")\n",
    "    return counter\n",
    "    \n",
    "def show_fp():\n",
    "    #predictions = get_predictions()\n",
    "    #tweets = checked_tweets[0].tolist()\n",
    "    counter = 0\n",
    "    for i in range(len(checked_tweets)):\n",
    "        if str(predictions[i]) != 'None' and checked_tweets[1][i] == 0:\n",
    "            counter += 1\n",
    "            #print(\"False Positive:\")\n",
    "            #doc = nlp(str(tweets[i]))\n",
    "            #if doc.ents:\n",
    "                #displacy.render(doc,style = \"ent\")\n",
    "    print(\"Number of False Positives: \", counter, \"\\n\")\n",
    "    print(\"Ratio of False Positives: \", round(counter/len(checked_tweets),3), \"\\n\")\n",
    "    return counter\n",
    "\n",
    "#test_data = pd.read_csv(TEST_DATA_PATH)\n",
    "test_data = pd.read_csv(PREDICTED_DATA_PATH)\n",
    "\n",
    "#y = test_data['food'].tolist()\n",
    "nlp = spacy.load(MODEL_PATH)\n",
    "#nlp = spacy.blank(\"en\")\n",
    "#print(nlp.pipe_names)\n",
    "#ent_recognize(\"My rice cakes is tasty\")\n",
    "#ent_recognize(\" peanut butter and jelly is the classic for me stuff that includes fruit sugars (like apples) are a good choice too imo\")\n",
    "\n",
    "\n",
    "# # Checking for overlapping words\n",
    "   \n",
    "#     print(data)\n",
    "# keywords = foodKeeperInfo()\n",
    "# testdata = convertToTrainingFormat(\"My rice cakes is tasty \", keywords)\n",
    "\n",
    "# # for word in keywords:\n",
    "# #     for word2 in wordsInFoodkeeper:\n",
    "# #         if word in word2 and word != word2:\n",
    "# #             print(word,word2)\n",
    "\n",
    "\n",
    "\n",
    "# ## Use the function below to check individual sentences\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# ent_recognize(\"my friend is chicken because he is scared\")\n",
    "# print(live_tweets)\n",
    "# testTweets = live_tweets[5]\n",
    "# for tweet in testTweets[:500]:\n",
    "#     if nlp(preProcess(tweet)).ents:\n",
    "#         ent_recognize(preProcess(tweet))\n",
    "\n",
    "\n",
    "print(predictions)\n",
    "# ## Use the function below to check model performance on the entire test set\n",
    "eval_model()\n",
    "\n",
    "# ## Use the functions below to see TP, TN, FP, FN respectively\n",
    "tp = show_tp()\n",
    "tn = show_tn()\n",
    "fn = show_fn()\n",
    "fp = show_fp()\n",
    "\n",
    "print(\"Precision: \", tp/(tp+fp))\n",
    "print(\"Recall: \", tp/(tp+fn))\n",
    "\n",
    "# foodkeeper = foodKeeperInfo()\n",
    "# print(foodkeeper)\n",
    "# sortedKeywords =  sorted(keywordRanker, key=keywordRanker.get, reverse=True)\n",
    "\n",
    "# for i in range(15): #sortedKeywords\n",
    "#     keywords.append(sortedKeywords[i])\n",
    "# print(keywords)\n",
    "# keywords.append(\"chicken\")\n",
    "# #keywords.append(\"cream cheese\")\n",
    "\n",
    "# abc = convertToTrainingFormat(\"I like to eat cream and cheese with chicken test\", keywords)\n",
    "# print(abc)\n",
    "\n",
    "# # See what keywords are found by the created model\n",
    "# keywordsFound = []\n",
    "# nlp = spacy.load(MODEL_PATH)\n",
    "# print(nlp.pipeline)\n",
    "# for tweet in live_tweets[5]: #test_data['tweet']:\n",
    "#     modeledTweet = nlp(preProcess(tweet))\n",
    "#     for token in modeledTweet.doc.ents:\n",
    "#         if str(token) in keywordsFound: continue\n",
    "#         keywordsFound.append(str(token))\n",
    "\n",
    "\n",
    "# # If the model finds food keywords print the Tweet\n",
    "# To help visualize which keywords are being found this loop iterates through the Tweets testing the model to see what keywords it finds. If it finds a keyword in the Tweet it will print the Tweet and highlight the keyword\n",
    "\n",
    "# for tweet in test_data['tweet'][:500]:\n",
    "#     ents = nlp(preProcess(tweet))\n",
    "#     #if ents.doc.ents:\n",
    "#     ent_recognize(preProcess(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c4c5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
